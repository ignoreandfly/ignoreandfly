---
title: "Vulnerability Analysis of Deep Learning Model for
OCTA Image Classification"
collection: publications
#permalink: https://link.springer.com/chapter/10.1007/978-981-97-6103-6_48
excerpt: 'The prevalence of Deep Learning in healthcare has revolutionized medical diagnostics, yet the vulnerability of these models to adversarial attacks threatens their security. This study investigates the susceptibility of a sophisticated deep learning model, trained to classify OCTA images as healthy or diabetic, to adversarial perturbations. Despite achieving high accuracy on unperturbed data, the model remains vulnerable to adversarial noise. The study employs techniques like Project Gradient Descent (PGD) and Fast Gradient Sign Method (FGSM) to generate adversarial examples and tests their efficacy against the model. Results show that even minor perturbations can lead to misclassification, emphasizing the need for adversarial robustness in healthcare models. As healthcare decisions are critical, incorporating adversarial training is must to mitigate the impact of adversarial vulnerabilities in deep learning-based medical diagnoses.'
date: 2024-10-02
venue: 'AICTC'
paperurl: 'https://link.springer.com/chapter/10.1007/978-981-97-6103-6_48'
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---
 *Munesh Chandra Trivedi*, **Siddhant Bharadwaj**,<br><br>
<!-- 
Recommended citation: Your Name, You. (2009). "Paper Title Number 1." <i>Journal 1</i>. 1(1). -->